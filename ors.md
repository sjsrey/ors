% Open Regional Science[^talk]
% Sergio J. Rey[^inst]

[^talk]: Draft Presidential Address to the Western Regional Science
Association, February 2014.

[^inst]: GeoDa Center for Geospatial Analysis and Computation, School of
Geographical Sciences and Urban Planning, Arizona State University.
<srey@asu.edu>

**DRAFT**

# Introduction

The title of this talk could have multiple meanings. If one were to  use *Open* as an adjective,  what would follow would be a discussion of the many ways in which our world of regional science has embraced openness. An alternative meaning would have *Open* as a verb in which case the talk that follows would be a call to arms for regional scientists to engage with open science and open source. 

Still another set of alternatives would see different punctuations of the tile, with a question mark as in *Open Regional Science?* or an exclamation point *Open Regional Science!*. The former questioning whether regional science is truly open, the latter more of a challenge.

As should be clear in what follows, the thrust of my argument is that the verb and exclamation point interpretations are the correct ones. Indeed my purpose in this talk is to situate regional science within the paradigm of open science by arguing that our future should be linked to open data, open modeling, open software, open collaboration, open publication, open funding and open education. open science opportunities related to [1] technology-driven developments to address big data challenges, [2] crowd powered / citizen science; [3] educational developments



The goal of this talk is t
Open science and culture arises from the open source software development
revolution.

Culture is broader than just open source software [@Sui:2013kx]
To engage regional science with open science I organize the talk around the
key dimensions of the open paradigm
In order to do so I first outline what the current state of affairs is regarding science, the commercialization of science and problems that we face as a community of scholars as a result of this commercialization.  This is followed by a more detailed examination of each of the components of open science and the extent to which they are operative in regional science with specific attention given to cases where there is a gap between potential and the opportunities they may afford us. I close the talk with some thoughts about the likely future for open regional science.


Start by defining terms. Since I've already declared my choice of xx for
*Open* that leaves two more terms to define before getting to the body of my
talk. 

Scientific publishing - issues - lead to reproducibility

This talk extends some themes I have been developing in previous work
[@Rey:2009xy; @Rey2012osgres].

# Science: Captured or Open

I, and I suspect many of you, take the *science* part of regional science seriously. We see science as one of the best constructions of human kind, running close to beer. We hold it in such high esteem as science as the noble goals helping us to:

- understand our world
- uncover new knowledge
- improve our realities for the betterment of human kind

Formal science has its origins in Descarte's Discourse on Methods in the 1637. From the beginning the concept of reproducibility was at the core. As  [@Schroeder:2013uq] notes the motto of the Royal Socieity 1671

>Nullius in Verba[^verba]

[^verba]: "Take nobody's word for it."

A key development in the advancement of early science was the decision by the Royal Socieity to publish results in the form of letters as a way to hasten dissemination relative to book publication. Alongside this, the tradition of relying on  three referees for each submitted letter began then and remains with us today.

Both the format and the process of early scienntific publishing had self-correction baked into them from the beginning. 

Use of three referees as a model for the review process dates back to this period.
Defining science can be done many ways, but a common approach is to break science down into components: theory, methods and data.  

## Commercialization
Outputs and components of the scientific process being increasingly seen as commercially valuable.
data
patents algorithms
publishing

## Scientific Publishing 
Time to publish on the web
- Typically 1 hour
- small marginal costs
- supports data and software pblication

contrast this with commercial publish. Time to publish an article from the date of submission typically is 1-2 years. The form of journals means that software and data are generally not included as part of the publication. And, the costs of commercial publishing are high, both on the production side of things where estimates are and average of 500 Euros per paper, but also on the access side of the coin where costs to read the same paper average 30 Euros. XXXGet statistics and sources here.
[@Schroeder:2013uq]

Subscription costs and Universities cancelling subscriptions. Elsevier boycott
UK open access mandate.

Curated or captured science is the result. Publishers own the copyright of the paper and have enclosed the theory within the confines of the article. Software and data are generally not to be found, even in cases where the paper access costs can be borne. 

Summary

Too much attention on documents as the only research artifact - data and software are not part of the discussion. Meta-analysis of research areas becomes prohibitively expensive - limits synthesis of knowledge. Science has been captured by commercial interests. All of this leads to major problems of irreproducibility. Essentially what is being compriised is:

>Science's capacity for self-correction comes from its openness to scruitiny and challenges

[@Boulton:2012kx]

If openennes is in question, science is in question.



Evolution of scientific publication.

Complexity in doing science, computation burden and related technological developments are challenging the traditional scientific publishing model. No longer does a regular lengthed paper in a hardbound journal adequately capture the scientific process underlying a research effort.

Reproducibility is almost invariably not possible in the current model


Career pressures sustain the curent model. Publish or perish has been the mantra we have adopted, leaving little or no time for ensuring that what we publish could in fact be reproduced by future scholars.

It should not come as surprise that the state of reproduciblity is so dismal.
## Reproducibility, fraud




Against these high profile cases of scientific fraud we must be cognizant of less well recognized, but arguably more widespread and therefor damaging forms of questionable scientific practices such as post-hoc theorizing, data fishing and so called p-hacking .  Estimates of the prevalence of dubious practices in pyschological research, such as collecting more data after seeeing whether results were significant or excluding data after looking at the impact of doing so, approach 100\% suggesting that rather than the exception, questionable research practices may constitute the "de facto research norm" [@John:2012fk pp. 525].

Are the social sciences any different from biomedical and other fields regarding misconduct? 

I doubt it.

At IRSR we have noticed an alarming increase in the number of blatant cases of double-submissions. As part of the submission process authors are required to check a box that indicates the manuscript is their original work and is not under consideration at any other journal. Most other journals have the same requirements so in the cases where this practice is caught, the offending authors have lied at least twice.

Prominent cases of plagerism, data cooking and fraud are replete in the social sciences. Frank Fischer, a political scientist at Rutgers, was accused by a graduate student and Alan Sokal [^sokal] of plagerism. Similar to the case of Doris Kearns Goodwin, the accused claimed that it was a case of sloppieness on their part rather than outright plagerism.[^gelman]

[^gelman]: For a running commentary of plagerism in the social sciences see the blog of Andrew Gelman at http://andrewgelman.com.

Reinhart and Rogoff case is a mixture of spreadsheet errors, omission of available data, favorable weighting and transcription. Followup studies have shown the magintude of the effect is reduced when these changes are incorporated, but not the sign. See [@Herndon:2013uq].




[^sokal]: The namesake of the *Sokal affair* in which the author submitted a completely nonsensical manuscript entitled "Transgressing the Boundaries: Towards a Transformative Hermeneutics of Quantum Gravity" to the journal *Social Text*.  After the paper was published Sokal revealed the hoax.

One ray of shining light is that the heros of these stories often tend to be graduate students who uncover the fraud or questionable practices.


##  Data Hoarding

In order for the network effects of open science to kick in a necessary condition will be that data underlying research projects be made accessible to the wider research community. Unfortunately, current institutional constraints and individual practices are standing in the way of realizing this.

### Privacy Concerns

There are important concerns regarding the protection of personal information on the one hand, and the rich set of empirical analyses that micro data support on the other. A number of strategies have been explored to strike this balance. Anonymization of public records attempt to minimize the risk of revealing information about individuals. However, this has its limit as a number of high profile failures have demonstrated.

One example being the case of the State of Massachusetts Group Insurance Commission (GIC) responsible for purchasing health insurance for state employees [@Sweeney:2005uq]. As part of that effort GIC anonymized data by removal of names, addresses, and Social Security numbers before releasing to researchers. What remained in the released data were ZIP code, birth date and gender of each person along with diagnoses and prescription information.

A researcher was able to purchase a voter registration list for Cambridge for $20 that contained the name, address, ZIP code, birth date and gender of each voter. Linking this with the GIC data made it possible to identify the medical records for the state govener, since only six people had the same birth date, of these three were men, and only one of these had the same ZIP code.

### Data Silos
Clearly there are problems with anonymization procedures and a very active research agenda is developing around privitatization XXXcites. An alternative to anonymization is the use of
save havens as secure sites for data containing sensitive person information with access being granted to authorized researchers. In the US, Census Research Centers play this role and offer remarkable opportunities for regional scientists to have access to micro data subject to a number of restrictions designed to ensure confidentiality. XXXrefs and details see mms proposal on numbers

Although the CRCs are  successful protecting privacy concerns I think it important to keep in mind that they also place limits on the network effect and science's self-correcting mechanism. This is because replication of studies that come out of CRC research is difficult if not impossible as any researcher seeking to do so requires access to the same data used in the original study. That access is only granted by the CRC which faces difficult choices in determining what proposals get approved for access, and given the choice between proposals for new novel studies versus studies that seek to replicate previous studies, it is conceivable that the former may be viewed more favorably.

Closely related to the issues surrounding CRCs are large data infrastructure projects funded by a variety of federal sources. These long running projects such as NHGIS, XXX have served a wide array of social scientists by developing comprehensive GIS datasets that span multiple time periods and spatial resolutions. The investments made in these projects have clearly yielded important benefits, and I in no way am criticizing the efforts of researchers at NHGIS. I am, however, raising the question of alternative models for data infrastructure projects that involve a diversity of institutions that in turn may result in even greater returns. Those models have not really been explored as there seems to be a form of institutional lock-in as the same institutions continue to secure funding to build on previous awards. 

Data constructed with public funds raises a vexing set of questions surrounding public access to those data. Court cases in NY and Orange county as examples of these issues.

Licensing data as and with software

Data hoarding is not limited to institutions as the problem can be found at the individual level as well. Our existing tenure and reward systems stress the number of publications produced and for researchers who have invested time and resources in constructing or acquiring unique data sets it is logical to seek a return on that investment by maximizing their exclusive use of the data. However, the individual scholar model doesn't really scale well and the opportunity costs from the scientist restricting access to the data by the wider scientific community have to be considered. After all, if the data is really wonderful, just image what might flow from releasing it to the field.

This doesn't have to be a zero sum game where the private gains are sacrificed for social goods - we can tweak the reward structure and attribution norms to make data provision a first class contribution to the scientific process. In other words, rather than the single scholar producing say a series of 5 papers with the exclusive use of the data, she produces one article and releases the data. This in turn empowers a larger group of scholars to generate vastly more than 5 papers using the same data, with each of these papers siting the single paper produced by the data generating/contribuing scholar. Her H-index would grow exponentially in this world rather than linearly in the hoarding model.

### Modeling Islands
Since the early days of regional science Walter Isard envisioned that integration would be a hallmark of our discipline. Channels of synthesis, efforts at integration, integrated modeling [@Hewings:2004fk].

It is sobering to contrast that grand vision with today's state of our modeling science. To a very real extent, integration of different modeling efforts has fallen far short of this vision. Rather than a rich ecosystem  of interconnected modeling components the silo business model appears to have won the day.  In part this reflects the economics of the regional modeling business were the development, continued enhancement and support of modeling frameworks requires stable and constant financial support.  Logically that support can be attracted through marketing efforts.

At the same time, we as a community of regional modelers have paid scant attention to model interoperability. A search of the leading proprietary regional models (REMI, IMPLAN) failed to turn up any references to application programing interfaces (API) which could be used to couple different modeling frameworks together. The finger should not just be pointed at proprietary modeling systems, as the academic community has also largely ignored interoperability concerns.

The lack of interoperability has hindered progress in the area of integrated modeling as much of the research effort has focused on the challenges of fusing existing modeling frameworks using different integration strategies [@Rey:2000df]. If model designers had paid more attention to interoperability, modularity and basic object oriented practices [@Jackson:1994hl] less of the research effort
would have been spent on refactoring integration strategies and more on enhancing  and applying integrated models to pressing regional economic issues.
This lack of interoperability is particularly worrisome given the growing recognition of the importance of research on coupled natural-human systems and the need for analytical frameworks to support inquiry. 


Link to commercialization of science argument




# Open Science
## Open Source ##


data, software, articles all need to be part of the scientific record and in open forms.
## Open Publication ##

meta analyses on fully explorable scientific records

Advances in cyberinfrasture are having impacts not just on how we *do* science but are likely to shape the ways we *report* science. The traditional vessel of reporting findings has been the regular journal article, which has served us well but as pointed out above, is showing its age. Tapping the possibilities of electronic publication opens up new ways to explore the scientific literature. As journal articles become *live* the ability to do more comprehensive analysis of the literature can be realized. Mining the relationships between publications, institutions, and knowledge domains can provide a richer narrative of science than what has been possible prior to the Web 2.0 age [@Ahlqvist:2013vn]. 

In the open publication model, I've articles also provide an entry point to access the data and methods that underlie an article. This lowers the barriers to replication of reported work by other scientists. 

It is exciting to contemplate the impact that this could have on research in regional science. Take the case of the literature on regional convergence  where a number of meta-analyses have attempted a synthesis of what we know about the processes of regional growth XXXcites. These entail an enormous amount of traditional literature review and careful extraction of estimation results from previous studies, the latter then used as inputs in meta-regressions to quantify the relationship between say speed of convergence and aspects of research design employed in the individual studies. But consider a meta-analysis on steroids where what is available to the meta-researcher is not just data in the form of the final estimation results of previous papers, but rather the original data, estimation code and software and ancillary materials used to generate the reported estimation results.

Specification searches can now be honestly reported in the  literature, giving us a 

publication bias

limited view of the research processs

Specification searches 

growing importance of grey literature

journal publications playing the role of providing an authoritative stamp 

issues of copyright and access have to be addressed for this model to become realized. Indeed, the technical solutions to implement the open publishing models are already with us. The major stumbling blocks are institutional  [@Ahlqvist:2013vn].


## Open Data ##


The increasing availability of open data is playing a pivotal role in the  the evolution of the so called *fourth paradigm of science*.  The classic pairing of experiment and theory (first and second paradigms) where married to the third paradigm of large-scale computational simulation in the mid-20th century. In this triad, data has provided observations about phenomena and was either collected to test particular theories or generated as output in process based simulations about those phenomena. In the fourth paradigm, data takes a more leading role in that application of exploratory and data mining technologies to massive and heterogeneous datasets are increasingly being used to generate, rather than test, new hypotheses.
Indeed the central role of data in this context is reflected in an alternative name for this fourth paradigm:  *data-intensive science* [@Tolle:2011fk].
## Open Models
## Open Collaboration: Release Early and Release Often
 Recall that the problems with publication pressures leading to dubious, in the worst case, or sloppy in the best, scholarly practices. Data analysis is not easy, and honest mistakes can and are made. Uncovering those mistakes is also not easy, especially in our current publishing system. The lack of replication infrastructure is a major impediment to identifying errors of both nefarious and honest species.

One possible antidote for this problem is to adopt  more open forms of collaboration. These would tap into  Linus's Law [@Himanen:2001dy]:
> Given enough eyeballs all bugs are shallow

In other words sunshine can be a strong disenfectant for the presence of scientific error as it strengthens the self-correction mechanism.

There are a range of open collaboration models that are possible differing in the extent to which the collaboration is implicit versus explicit. An example of the implicit approach can be seen in this manuscript as I opted to make the entire writing process transparent by placing the drafts on GitHub.[^ors] By doing so, I have made the materials available to whoever is interested in reading the evolving manuscript. Readers who take the time to submit bug reports, or pull requests containing suggestions for additions, deletions and edits would represent collaborators. 

[^ors]: The GitHub repository for the paper is at https://github.com/sjsrey/ors

While accessing feedback through the implicit collaboration model is a potential benefit, I think the real value in this model is that it captures the full evolution of the research artifact. From a technical standpoint GitHub enables a tracking of the history of all the files in a project, not to mention off-site backup. At the same time, deciding to open up your project at a very early stage does have a subtle, but important, influence on how you approach your work. In the end, it does not really matter to me whether collaborators are realized in bug reports (or feature requests) - just knowing that potentially there are readers externalizes Adam Smith's impartial observer [@Smith:2001fk]. And it does so very early in the process rather than at the final stage of manuscript submission.

More along the spectrum towards the formal collaboration model is the example of 

 XXXLink to open publishing model - maybe a better distinction is between formal and informal collaboration - the former being referees assigned to a paper while informal is open to anyone who contributes to improving the manuscript.





A prominent theme in the recent literature on open science is reproducibility.
General issues with the commercialization of science

lay out the problem

link the inspiration from open source


reproducibility

closed science depletion of a common resource


open funding and kick starter crowdfunding initiatives

For science to be truly open, two components need to be operative. *Open data* constitutes available, intelligible, asssessible and useable data.  *Open access*  to scientific publications and knowledge allows the realization of the building on shoulders of giants XXXget quote. Accessbility is more than the ability to acquire since a key impediment to scientific progress is that much published research is unintelligible beyond the origin specialist domain. This effective communication of results and methods is paramount [@Boulton:2012kx].

### Open Source







data archives needed

Open Data Charter  [@Eaves:2013fk] is a recognition that in addition to fostering innovation and transparency, open data can also drive public policy.

US Government opendatanow.com geoplatform.gov geo.data.gov

### Open Modeling

UrbanSim as an exception


Interoperabiity and open modeling are vital to our ability to move regional
science into the high performance computing era.

open science piece on challenges of urban systems

integration of multi scalar processes - regional grown and intraurban spatial structure.

OGC, City GML, Water ML, open modeling initiative (all hands meeting)


### Open Collaboration

what open questions in regional science should we be addressing

### Open Publishing

There are signs that alternative open models for scientific publishing are beginning to get traction. A recent example that I had exerience with was the publication of the conference proceedings for the 2013 Scientific Computing with Python (SciPy2013) conference. The entire process was produced using open source tools, including GitHub for file submission, reviewing and ultimately publishing. Authors were provided with templates to build their papers and these templates using *ReStructuredText* were made available via a *forking* of the proceedings GitHub repository. When their paper was ready for submission, the authors issued a *pull request*. Once the pull request was merged, the editors contacted referees via a web form and the reviews were then integrated into the GitHub repository. Authors were then asked to respond to the comments and submit a new pull request for the revised version. The final accepted versions of the papers were published in the proceedings [@scipy:2013vn] as an open-access publication distributed under the terms of the *Creative Commons Attribution License*.

Several aspects of this process are worth noting. The process relied on technologies that were already familiar to this community of scholars who use code repositories for collaboration on the development of scientific software on a regular basis.  In addition to the technologies,  the traditional roles of author, reviewer, and editor were mapped into those of participants in an open source software development model is innovative. In this model developers (authors) wishing to contribute a new software feature (article) to a field issue a pull request (submission) to the project (journal). That pull request (manuscript submission) is then reviewed by the community (editor and reviewers) and bug reports (referee reports) are submitted. The developer (author) then incorporates the feedback from the bug report (reviews) into the manuscript and updates the pull request (revision submission). 

At the end of the process the project maintainer (editor), has to make a final decision. The pull request would be merged in the case where the paper is accepted, or simply closed but not merged if the paper were rejected. In the former case the paper would appear in the final published proceedings. In contrast to the traditional publication model however, papers that were rejected in the process actually remain in the repository as the trail of pull requests, bug reports and publication decisions is available for all to see.

Perhaps more importantly, this design enhanced the collaborative nature of the enterprise as the reviewers took on roles of allies in helping to improve the papers. This stood in stark contrast to the traditional review process in which papers can be shredded by reviewers. At the same time, the open source model was highly efficient as the review process started with an initial pull request deadline of May 19th and final publication of the proceedings just over two months later. The organization of the review process akin to  an open source software development model tapped into the power of community and is a clear reflection that science publication is not a solitary endeavor but rather can   is done by groups of scholars.

Scipy 2013 example 
Highlight collaborative process from the blog post

Give overview of the process

### Open Education


Web book of regional science as an exemplar



### Institutions

Academia second most conservative instution every invented, next to opera

Academic reward system

Ironically, it would appear that open source and academic science have been largely separated at birth. Linus Torvalds, the creator of the Linux kernel and arguably one of the major figures in the open source movement, expressed his disenchantment with the state of operating systems research in academia as a motivation for leaving the university [@Moody:2001vg].



### Commercialization of Science


### Scientific Publishing

Concerns about scientific software [@Joppa17052013; @Yalta:2010xq].


austerity debacle


## Peer Review


## Open Community

notion of "open people"

importance of community

strength of regional science is its interdisciplanary outlook

## Conclusion

Way forward will represent a mixture of open and proprietary regional science. This hybrid model will, however, represent a rebalancing of many components of regional science as it engages with open science. Our choice is whether that engagement takes an active or passive form.

To close this talk I think regional scientists (actually all scientists) would do well by taking the Dalai Lama's recommendation to heart:

> Share your knowledge, it is a way to achieve immortality.


# References




